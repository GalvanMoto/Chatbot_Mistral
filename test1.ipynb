{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GAUTA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:24<00:00,  3.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with watchdog (windowsapi)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GAUTA\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from diffusers import DiffusionPipeline, EulerAncestralDiscreteScheduler\n",
    "import uuid\n",
    "import transformers\n",
    " \n",
    "app = Flask(__name__)\n",
    " \n",
    "USE_PEFT_BACKEND = False\n",
    " \n",
    "# Check if PEFT backend is available\n",
    "if hasattr(transformers, \"pipelines\"):\n",
    "    if hasattr(transformers.pipelines, \"PEFTBackend\"):\n",
    "        USE_PEFT_BACKEND = True\n",
    " \n",
    "# Initialize the DiffusionPipeline with the pre-trained model\n",
    "pipeline = DiffusionPipeline.from_pretrained(\"fluently/Fluently-XL-v2\")\n",
    "pipeline.scheduler = EulerAncestralDiscreteScheduler.from_config(pipeline.scheduler.config)\n",
    " \n",
    "# Load the weights for DALL·E model\n",
    "if USE_PEFT_BACKEND:\n",
    "    pipeline.load_lora_weights(\"ehristoforu/dalle-3-xl-v2\", weight_name=\"dalle-3-xl-lora-v2.safetensors\", adapter_name=\"dalle\")\n",
    " \n",
    "def save_image(img):\n",
    "    unique_name = str(uuid.uuid4()) + \".png\"\n",
    "    img.save(unique_name)\n",
    "    return unique_name\n",
    " \n",
    "@app.route('/generate_image', methods=['POST'])\n",
    "def generate_image():\n",
    "    data = request.json\n",
    "    text_prompt = data.get('text_prompt', '')\n",
    " \n",
    "    # Generate the image based on the textual prompt\n",
    "    images = pipeline(\n",
    "            prompt=text_prompt,\n",
    "            negative_prompt=\"\",\n",
    "            width=512,\n",
    "            height=512,\n",
    "            guidance_scale=3,\n",
    "            num_inference_steps=15,\n",
    "            num_images_per_prompt=1,\n",
    "            cross_attention_kwargs={\"scale\": 0.70},\n",
    "            output_type=\"pil\",\n",
    "        ).images\n",
    "   \n",
    "    image_paths = [save_image(img) for img in images]\n",
    "   \n",
    "    return jsonify({\"image_paths\": image_paths})\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.llms import CTransformers\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain import PromptTemplate\n",
    " \n",
    "# Define the template for the prompt\n",
    "prompt_template_twitter = \"\"\"Generate a list of two varied versions of Twitter post sequences. \\\n",
    "    The topic of the post is as follows:\n",
    "   \n",
    "    current conversation:{history}\n",
    "    Human: {input}\n",
    "   \n",
    " \n",
    "    You are required to write it in English. Keep it fun to read by adding some emojis and supporting hashtags (just if you think it's necessary).\n",
    " \n",
    "    Output it as an array with  2 JSON items format with the following keys:\n",
    "    - version: <version 1/2>,\n",
    "    - tweet: <the tweet, each thread separated by the number of the sequence and new line char>\n",
    "    \"\"\"\n",
    " \n",
    "# Function to get user input for the prompt\n",
    "def get_user_prompt():\n",
    "    query = input(\"Enter your query: \")\n",
    "    return query\n",
    " \n",
    "# Instantiate the PromptTemplate with the template and input variables\n",
    "# prompt = PromptTemplate(template=prompt_template, input_variables=['query'])\n",
    "prompt_twitter = PromptTemplate( input_variables=['history','input'],template=prompt_template_twitter)\n",
    "# Instantiate the CTransformers model\n",
    "llm = CTransformers(model=\"./mistral-7b-instruct-v0.2.Q4_K_M.gguf\",\n",
    "                    model_type=\"llama\",\n",
    "                    max_new_tokens=4000 ,\n",
    "                    temperature=0.2)\n",
    " \n",
    "# Instantiate the LLMChain with the prompt and llm\n",
    "# llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "conversation=ConversationChain(\n",
    "    prompt=prompt_twitter,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=ConversationBufferWindowMemory(k=2)\n",
    "   \n",
    ")\n",
    "# Define a function to handle user interaction\n",
    "def main():\n",
    "    while True:\n",
    "        # Get user input for the prompt\n",
    "        user_prompt = get_user_prompt()\n",
    " \n",
    "        # Run the LLMChain with the user input prompt\n",
    "        llm_response = conversation.run(input= user_prompt)\n",
    " \n",
    "        # Print the response\n",
    "        print(llm_response)\n",
    " \n",
    "        # Ask if the user wants to ask another question\n",
    "        another_question = input(\"Do you want to ask another question? (yes/no): \")\n",
    "        if another_question.lower() != 'yes':\n",
    "            break\n",
    " \n",
    "# Call the main function to start the interaction\n",
    "main()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.1.14)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.30 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain) (0.0.31)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.37 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain) (0.1.40)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain) (0.1.40)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain) (2.6.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain-core<0.2.0,>=0.1.37->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2->langchain) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: CTransformers in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.2.27)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from CTransformers) (0.22.2)\n",
      "Requirement already satisfied: py-cpuinfo<10.0.0,>=9.0.0 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from CTransformers) (9.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub->CTransformers) (3.13.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub->CTransformers) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub->CTransformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub->CTransformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub->CTransformers) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub->CTransformers) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub->CTransformers) (4.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.42.1->huggingface-hub->CTransformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->huggingface-hub->CTransformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->huggingface-hub->CTransformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->huggingface-hub->CTransformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gauta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->huggingface-hub->CTransformers) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install CTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GAUTA\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\GAUTA\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGenerate a list of two varied versions of proposal sequences. The topic of the proposal is as follows:\n",
      "\n",
      "current conversation: \n",
      "Human: Generate a proposal for Convince the client of the return on investment (ROI) and long-term benefits of our proposed solution.\n",
      "\n",
      "You are required to write it in a formal but engaging tone. Make sure to include all necessary details and sections in the proposal.\n",
      "\n",
      "Output it as an array with 2 JSON items format with the following keys:\n",
      "- version: <version 1/2>,\n",
      "- proposal: <the proposal, each section separated by the name of the section and a new line char>\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "---\n",
      "Version 1:\n",
      "[\n",
      "  {\n",
      "    \"version\": \"Version I: Value-Driven ROI Proposal\",\n",
      "    \"proposal\": \"**Executive Summary:**\\nOur proposed solution offers significant value to your business. The short-term benefits include increased productivity and efficiency, while the long-term advantages encompass cost savings, improved customer satisfaction, and enhanced competitive positioning.\\n\\n**Business Case:**\\nOur extensive research shows that our solution is the market leader in terms of functionality and usability. Implementation will result in a quick return on investment (ROI), typically within 6-12 months for businesses of your size. Additionally, our solution has a proven track record of delivering long-term benefits, such as increased productivity by up to 30% and reduced operational costs by an average of 25%. \\n\\n**Value Proposition:**\\nOur solution's key differentiators include: seamless integration with existing systems; dedicated onboarding and training services; continuous product enhancements; and a customer success team committed to your business growth. \\n\\n**ROI Calculation:**\\nWe have prepared a detailed ROI calculation based on\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import CTransformers\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "# Define the template for the proposal prompt\n",
    "prompt_template_proposal = \"\"\"Generate a list of two varied versions of proposal sequences. The topic of the proposal is as follows:\n",
    "\n",
    "current conversation: {history}\n",
    "Human: {input}\n",
    "\n",
    "You are required to write it in a formal but engaging tone. Make sure to include all necessary details and sections in the proposal.\n",
    "\n",
    "Output it as an array with 2 JSON items format with the following keys:\n",
    "- version: <version 1/2>,\n",
    "- proposal: <the proposal, each section separated by the name of the section and a new line char>\n",
    "\"\"\"\n",
    "\n",
    "# Function to get user input for the proposal prompt\n",
    "def get_user_prompt():\n",
    "    query = input(\"Enter your proposal prompt: \")\n",
    "    return query\n",
    "\n",
    "# Instantiate the PromptTemplate with the proposal template and input variables\n",
    "prompt_proposal = PromptTemplate(input_variables=['history', 'input'], template=prompt_template_proposal)\n",
    "\n",
    "# Instantiate the CTransformers model\n",
    "llm = CTransformers(model=\"./mistral-7b-instruct-v0.2.Q4_K_M.gguf\",\n",
    "                    model_type=\"llama\",\n",
    "                    max_new_tokens=4000,\n",
    "                    temperature=0.2)\n",
    "\n",
    "# Instantiate the ConversationChain with the proposal prompt and llm\n",
    "conversation = ConversationChain(\n",
    "    prompt=prompt_proposal,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=ConversationBufferWindowMemory(k=2)\n",
    ")\n",
    "\n",
    "# Define a function to handle user interaction\n",
    "def main():\n",
    "    while True:\n",
    "        # Get user input for the proposal prompt\n",
    "        user_prompt = get_user_prompt()\n",
    "\n",
    "        # Run the ConversationChain with the user input prompt\n",
    "        llm_response = conversation.run(input=user_prompt)\n",
    "\n",
    "        # Print the response\n",
    "        print(llm_response)\n",
    "\n",
    "        # Ask if the user wants to ask another question\n",
    "        another_question = input(\"Do you want to generate another proposal? (yes/no): \")\n",
    "        if another_question.lower() != 'yes':\n",
    "            break\n",
    "\n",
    "# Call the main function to start the interaction\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
